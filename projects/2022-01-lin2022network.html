<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction | STARS Lab</title><meta name="generator" content="Jekyll v3.8.6" /><meta property="og:title" content="Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction" /><meta name="author" content="Lei Lin, Weizi Li, and Lei Zhu" /><meta property="og:locale" content="en_US" /><meta name="description" content="Lei Lin1, Weizi Li2, and Lei Zhu3 1University of Rochester 2University of Memphis 3University of North Carolina at Charlotte" /><meta property="og:description" content="Lei Lin1, Weizi Li2, and Lei Zhu3 1University of Rochester 2University of Memphis 3University of North Carolina at Charlotte" /><link rel="canonical" href="http://localhost:4000/projects/2022-01-lin2022network" /><meta property="og:url" content="http://localhost:4000/projects/2022-01-lin2022network" /><meta property="og:site_name" content="STARS Lab" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-20T20:53:12-05:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction" /><meta name="twitter:site" content="@ronaldsvilcins" /><meta name="twitter:creator" content="@Lei Lin, Weizi Li, and Lei Zhu" /> <script type="application/ld+json"> {"@type":"BlogPosting","url":"http://localhost:4000/projects/2022-01-lin2022network","headline":"Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction","dateModified":"2022-07-20T20:53:12-05:00","datePublished":"2022-07-20T20:53:12-05:00","author":{"@type":"Person","name":"Lei Lin, Weizi Li, and Lei Zhu"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/projects/2022-01-lin2022network"},"description":"Lei Lin1, Weizi Li2, and Lei Zhu3 1University of Rochester 2University of Memphis 3University of North Carolina at Charlotte","@context":"https://schema.org"}</script><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="STARS Lab" href="/atom.xml"><link rel="alternate" title="STARS Lab" type="application/json" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /><link href="https://fonts.googleapis.com/css?family=Cormorant+Garamond:500" rel="stylesheet"><style type="text/css"> *,*:before,*:after{box-sizing:inherit;margin:0;padding:0}html{box-sizing:border-box}body{font-family:'Cormorant Garamond', serif;background-color:#fafafa;color:#000;font-size:1rem;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility}a,a:visited{border:0;padding:0;text-decoration:none;color:#003087;font-weight:600}a:hover{color:#666}h1,h2{text-align:center;font-weight:500}h3{font-weight:500}ul{list-style-type:square;margin-left:2rem}header,main{margin:0 auto;max-width:50rem}img{width:100%}footer{font-family:'Inter', 'Helvetica', sans-serif;margin:1rem 0;text-align:center}.section{position:relative}.section a{opacity:1;-webkit-transition:opacity .2s}.section a:hover{opacity:0.8;-webkit-transition:opacity .2s}.imglabel{position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);visibility:hidden;opacity:0;transition:opacity .2s}.section:hover .imglabel{visibility:visible;opacity:1;transition:opacity .2s}.label{font-family:'Inter', 'Helvetica', sans-serif;font-size:1.8rem;color:white;font-weight:400;transition:.2s}.logo{height:7rem;width:auto;margin-top:2rem;margin-bottom:.5rem}.webicon{width:1rem}.trigram{width:1.1rem;margin-right:.5rem}.alignright{text-align:right;margin-right:1rem}.alignleft{text-align:left}.aligncenter{text-align:center}.caption{font-size:1.1rem;font-style:italic;text-align:center}.thumbnail{width:168px;height:120px}.thumbnailright{width:168px;height:120px;margin-left:auto}.itemgrid{display:flex;flex-wrap:wrap;display:grid;grid-template-columns:1fr;grid-auto-rows:minmax(0rem, auto);grid-gap:1.2rem}.item{display:flex;align-items:left;justify-content:left;position:relative;flex:1 1 10rem}.frame{padding:1rem;font-size:1.3rem;-webkit-box-shadow:0 0.75rem 1.5rem rgba(18,38,63,0.03);box-shadow:0 0.75rem 1.5rem rgba(18,38,63,0.03);background-color:white;border-radius:10px}.frame h2{font-size:2rem}.frame h3{font-weight:0}.members{justify-content:center;text-align:center;display:flex;flex-wrap:wrap}.person{width:14.6rem;margin:0 0 1.2rem 0}.headshot{width:150px}.role{font-size:1.2rem;color:#666}.news{margin:0 1.4rem 0}.news p{margin:0 0 0.6rem 0}.news a{color:#41b6e6}.newstitle{font-size:1.5rem;color:#003087;font-weight:600}.newsinfo{font-size:0.8rem;text-transform:uppercase;letter-spacing:.1em;font-family:'Inter', 'Helvetica', sans-serif;color:#999}.newscontent{font-size:.9rem;line-height:1.3rem;font-family:'Inter', 'Helvetica', sans-serif;color:#666}.paper{margin:0 1.4rem 0}.paper p{margin:0 0 .2rem 0}.papertitle{font-size:1.3rem}.paperauthor{font-size:1.2rem}.papervenue{font-style:italic;font-size:1.1rem}#slider{overflow:hidden}#slider figure{position:relative;width:500%;margin:0;left:0;animation:20s sliding infinite}#slider figure img{width:20%;float:left}@keyframes sliding{0%{left:0}20%{left:0}25%{left:-100%}45%{left:-100%}50%{left:-200%}70%{left:-200%}75%{left:-300%}95%{left:-300%}100%{left:-400%}}blockquote{background:#f9f9f9;border-left:5px solid black;font-size:120%;margin:2rem 0;padding:1rem}blockquote p{margin:0}blockquote footer{font-size:80%;margin:1rem 0 0 0}dl dt{margin-bottom:0.5rem}dl dd{font-style:italic;margin-bottom:2rem}code,.highlight{background:#edf2f7;padding:0.1rem 0.3rem;font-size:1.1rem}pre{background:#edf2f7;padding:1em;font-size:.8rem;overflow:scroll}.iframe{position:relative;width:100%;overflow:hidden;padding-top:56.25%}.responsive{position:absolute;top:0;left:0;bottom:0;right:0;width:100%;height:100%;border:none}</style></head><body><header></header><main id="main" role="main"> <a href="/"><img class="logo" src="/images/logo/p.png"></a><div class="frame"><h2>Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction</h2><br><p class="aligncenter">Transportation Research Board 101st Annual Meeting (TRB), 2022</p><br><p class="aligncenter"> <a href="http://urdata.net/">Lei Lin</a><sup>1</sup>, <a href="https://weizi-li.github.io/">Weizi Li</a><sup>2</sup>, and <a href="https://sites.google.com/site/zhulei0717/home">Lei Zhu</a><sup>3</sup> <br /> <sup>1</sup>University of Rochester <br /> <sup>2</sup>University of Memphis <br /> <sup>3</sup>University of North Carolina at Charlotte</p><p><br /></p><p><img src="/projects/Lin2022Network/teaser.png" alt="teaser" /></p><p class="aligncenter"> Temporal prediction performance (errors) of 6 models (1 step = 1 hour)</p><p><br /></p><p><img src="/projects/Lin2022Network/teaser2.png" alt="teaser" /></p><p class="aligncenter"> Temporal prediction performance (errors) of 6 models (1 step = 15 minutes)</p><p><br /></p><h3 id="abstract">Abstract</h3><p>Accurate prediction of network-wide traffic conditions is essential for intelligent transportation systems. In the last decade, machine learning techniques have been widely used for this task, resulting in state-of-the-art performance. We propose a novel deep learning model, Graph Convolutional Gated Recurrent Neural Network (GCGRNN), to predict network-wide, multi-step traffic volume. GCGRNN can automatically capture spatial correlations between traffic sensors and temporal dependencies in historical traffic data. We have evaluated our model using two traffic datasets extracted from 150 sensors in Los Angeles, California, at the time resolutions one hour and 15 minutes, respectively. The results show that our model outperforms the other five benchmark models in terms of prediction accuracy. For instance, our model reduces MAE by 25.3%, RMSE by 29.2%, and MAPE by 20.2%, compared to the state-of-the-art Diffusion Convolutional Recurrent Neural Network (DCRNN) model using the hourly dataset. Our model also achieves faster training than DCRNN by up to 52%.</p><p><br /></p><h3 id="links">Links</h3><ul><li><a href="https://arxiv.org/abs/2111.11337">Preprint</a></li><li><a href="">Publication</a></li><li><a href="https://github.com/leilin-research/GCGRNN">Code</a></li></ul><p><br /></p><h3 id="citation">Citation</h3><pre>
@InProceedings{Lin2022Network,
  author = {Lei Lin and Weizi Li and Lei Zhu},
  title = {Data-driven Graph Filter based Graph Convolutional Neural Network Approach for Network-Level Multi-Step Traffic Prediction},
  booktitle = {Transportation Research Board 101th Annual Meeting (TRB)},
  year = {2022}
}
</pre><p><br /></p><h3 id="contact">Contact</h3><p>Lei Lin (lei.Lin@ieee.org), Weizi Li (wli@memphis.edu), and Lei Zhu (lei.zhu@uncc.edu)</p><p><br /></p><h3 id="acknowledgements">Acknowledgements</h3><p>The authors would like to thank the University of Memphis for providing the start-up fund.</p><br> <br><div> <a href="/projects">&#8592; All Publications</a></div></div><br><hr style="height:2px; border:none; background-color:#e7e9ee;"></main><footer class="footer" role="contentinfo"> <small>&copy; STARS Lab</small></footer></body></html>
